#-------------------------------------------------------
# xintonglu
#-------------------------------------------------------
debug: True
name: xtl
module:
 - al.zip
cmd:
  loc: "./rdc_timeseries_xtl.py"
  option:
    - ["c", "cate", "--c cate", False, 0]
    - ["d", "DC", "--d", False, 0]
    - ["ps", "fr begin date", "--ps fr begin date", False,0]
    - ["pe", "fr end date", "--pe fr end date", False, 0]
    - ["period", "period", "--period period", False, 7]
    - ["predict_num", "fr days", "--predict_num fr days", False, 13]
    - ["badsku", "SKU", "--badsku ", False, None]
task:
  name: "rdc_lr_fr_{name}"
  spark:
    shell:
      - [--master, yarn-client]
      - [--num-executors, 10]
      - [--executor-memory, 5g]
      - [--executor-cores, 4]
      - [--driver-memory,10g]
      - [--queue, root.bdp_jmart_cmo_ipc_union.bdp_jmart_ipc_spark]
      - [--conf, spark.pyspark.python=python2.7]
      - [--spark.default.parallelism, 100]
      - [--py-files, "conf_lr.py,alEnv_xtl.py"]
    set: ~
  hive: ~
dfs:
  name_node: ns15
  data_mart: cmo_ipc
  base: hdfs://{dfs.name_node}/user
  dfs  : "{dfs.base}/{dfs.data_mart}"
  hive  : "{dfs.dfs}/<?e>.db"
model:
  dc_list:
    - 3
    - 4
    - 5
    - 6
  url:
    input:
      - timeseries:
        - "{dfs.hive}/app_sfs_xtl_ts/key=salesForecast"
        - "{dfs.hive}/app_sfs_xtl_ts/key=priceBeforeDiscount"
        - "{dfs.hive}/app_sfs_xtl_ts/key=priceAfterDiscount"
        - "{dfs.hive}/app_sfs_xtl_ts/key=stockQuantity"
        - "{dfs.hive}/app_sfs_xtl_ts/key=vendibility"
      - cate_seasonal:
         isBook: False
      - calendar:
        - b: "{y}-01-01"
        - e: "{y}-12-31"
      - promotion: ~
    output:
      dir: "{dfs.dfs}/rdc_forecast_results_lr_xtl/dt={v_ps}/forecast_{dc}_{cate}"
      file: "{model.url.output.dir}/result_{period}_{predict}"